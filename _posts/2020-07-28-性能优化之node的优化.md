---
layout: post
title: 性能优化之Node的优化
subtitle: 性能优化之Node的优化
date: 2020-07-28
author: Qi
header-img: img/404-bg.jpg
catalog: true
tags:
  - 性能优化
---

# 数据传输用buffer替代string
当使用buffer替代string传输数据时，效率大概能够提高20%。
```
const http = require('http');

let s = '';
for (let i = 0; i < 1024 * 10; i++) {
  s += 'a';
}

const str = s;
const buffStr = Buffer.from(s);

const server = http.createServer((req, res) => {
  if (req.url == '/buffer') {
    res.end(buffStr);
  } else if (req.url == '/') {
    res.end(str);
  }
});
server.listen(3002);

```
运用wrk进行测试（第一次的测试为buffer,第二次为string），可以获知buffer的传输效率高于string。
![Image text](/img/WechatIMG263.png)

# 使用 fast-json-stringify 加速 JSON 序列化

在日常开发中经常使用const json = JSON.stringify(obj)使用json字符串，可以使用fast-json-stringify 替换JSON.stringify，这就大大减少了计算开销。


```
const fastJson = require('fast-json-stringify')
const stringify = fastJson({
    title: 'Example Schema',
    type: 'object',
    properties: {
        name: { type: 'string' },
        age: { type: 'integer' },
        books: {
            type: 'array',
            items: {
                type: 'string',
                uniqueItems: true
            }
        }
    }
})
```
> 在 Node.js 的中间件业务中，通常会有很多数据使用 JSON 进行传输，并且这些 JSON 的结构是非常相似的（如果你使用了 TypeScript，更是这样），这种场景就非常适合使用 JSON Schema 来优化。


# 优化 V8 GC
在日常开发中造成内存泄漏的主要原因有两个：
- 老生代内存空间不够。
- 瞬间传入的内存过大，新生代内存空间不够，导致无法进行GC。

容易踩到下面几个坑：

**利用大对象进行缓存，导致老生代的垃圾回收过慢，或者造成内存泄漏**

这里使用了一个leakArray作为全局对象，当用户多次访问的时候，leakArray会被加到老生代中，并且会越来越大，最后造成内存泄漏。可以通过memeye检查对应的变化。
```
const http = require('http');
const memeye = require('memeye');
memeye();
let leakArray = [];
const server = http.createServer((req, res) => {
  if (req.url == '/') {
    leakArray.push(Math.random());
    res.end('hello world');
  }
});
server.listen(3000);
```
解决方法：
- 使用redis对大对象进行缓存，
- 限制本地缓存对象的大小，比如使用 FIFO、TTL 之类的机制来清理对象中的缓存。
- 将leakArray使用万后设置为null(此种方法不一定有用，当leakArray做完其他绑定对象的key时，设置成null不起作用)

```
 //返回当前Node.js使用情况
console.log('第一次', process.memoryUsage());

let map = new Map();
let leakArray = new Array(5 * 1024 * 1024);
map.set(leakArray, 1);
global.gc();
console.log('第二次', process.memoryUsage());

leakArray = null;
console.log('第三次', process.memoryUsage());

//解除绑定leakArray后才会起作用
map.delete(leakArray);
leakArray = null;
global.gc();
console.log('第三次', process.memoryUsage());

```

- 使用weakSet、weakMap替代，WeakSet 和 WeakMap。它们对于值的引用都是不计入垃圾回收机制的，所以名字里面才会有一个"Weak"，表示这是弱引用。

```
console.log('第一次', process.memoryUsage());
const wm = new WeakMap();
let key = new Array(5 * 1024 * 1024);
wm.set(key, 1);
key = null;
global.gc();
console.log('第二次', process.memoryUsage());
```

**新生代空间不足，导致无法GC**

Node.js 默认给新生代分配的内存是 64MB（64位的机器，后同），但因为新生代 GC 使用的是 Scavenge 算法，所以实际能使用的内存只有一半，即 32MB,这个空间很容易就会被占满，解决方法是在启动 Node.js 时，修改新生代的内存上限

```
node --max-semi-space-size=128 app.js
```

# 提升 Promise 的性能

Promise,async/await 是解决回调嵌套地狱的灵丹妙药,优雅的语法后面也隐藏着性能损耗使用 github 上一个已有的跑分项目进行测试，以下是测试结果：
```
file                               time(ms)  memory(MB)
callbacks-baseline.js                   380       70.83
promises-bluebird.js                    554       97.23
promises-bluebird-generator.js          585       97.05
async-bluebird.js                       593      105.43
promises-es2015-util.promisify.js      1203      219.04
promises-es2015-native.js              1257      227.03
async-es2017-native.js                 1312      231.08
async-es2017-util.promisify.js         1550      228.74

Platform info:
Darwin 18.0.0 x64
Node.JS 11.1.0
V8 7.0.276.32-node.7
Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz × 4
```

从结果中看到，原生 async/await + Promise 的性能比 callback 要差很多，并且内存占用也高得多。对于大量异步逻辑的中间件项目而言，这里的性能开销还是不能忽视的。

所以对于大量异步逻辑、轻量计算的中间件项目而言，可以在代码中把全局的 Promise 换为 bluebird 的实现：
```
global.Promise = require('bluebird');
```

# 正确使用stream

Stream 是 Node.js 最基本的概念之一，Node.js 内部的大部分与 IO 相关的模块，比如 http、net、fs、repl，都是建立在各种 Stream 之上的。

- 对于大文件，我们不需要把它完全读入内存，而是使用 Stream 流式地把它发送出去：

```
const http = require('http');
const fs = require('fs');

// bad
http.createServer(function (req, res) {
    fs.readFile(__dirname + '/data.txt', function (err, data) {
        res.end(data);
    });
});

// good
http.createServer(function (req, res) {
    const stream = fs.createReadStream(__dirname + '/data.txt');
    stream.pipe(res);
});
```

在业务代码中合理地使用 Stream 能很大程度地提升性能，当然是但实际的业务中我们很可能会忽略这一点，比如采用 React 服务器端渲染的项目，我们就可以用renderToNodeStream：

```
const ReactDOMServer require('react-dom/server')
const http = require('http')
const fs = require('fs')
const app = require('./app')

// bad
const server = http.createServer((req, res) => {
    const body = ReactDOMServer.renderToString(app)
    res.end(body)
});

// good
const server = http.createServer(function (req, res) {
    const stream = ReactDOMServer.renderToNodeStream(app)
    stream.pipe(res)
})

server.listen(8000)
```

# 参考

https://zhuanlan.zhihu.com/p/50055740