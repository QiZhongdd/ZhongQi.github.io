**v8如何执行一段js**

- 首先准备基础环境，基础环境包括执行上下文、调用栈、堆、作用域等
- 然后将代码解析成Ast树，同时生成作用域
- 生产ast树后转换成字节码，字节码会交给解释器执行。当一段代码被反复执行的时候会被标记成热点代码，解释器会将热点代码交给编译器编译成二进制代码，待下次执行热点代码的时候直接执行二进制代码，这个时候效率会有所提升。
- 但由于js是动态语言，如果执行的时候js的相关对象结构发生变化，那么编译器会进行反优化，将反优化的代码交给解释器执行
- 由于解释器与编译器之间有优化空间，v8年初的时候在两者之间添加了 Sparkplug,效率提升了5%到10%。
  
**快属性和慢属性**

首先v8会将对象的属性划分成element属性和protities属性，element属性用来保存key值为数字类型的属性。其他类型的属性被称为protities属性。protities属性又分为快属性和慢属性。当protities属性的数量小于一定数量（默认是10个）的时候回保存在对象内，被称为对象内属性，也被称为快属性。如果超过一定数量，那么多余的属性会被保存在为非线性的字典存储模式，这个时候查找效率会有所降低。所以被称为慢属性，这也是为什么vue2声明了很多属性查找变慢的原因。

数组能够方便快速查找，但删除和插入不是很友好。JSArray继承了JSObject,所以他能保存任意类型的数据,数组又分为快数组和满数组，所谓的快数组时类似于数组的类，是一块连续的存储空间，可以直接用索引定位。能够动态的扩容和减容。而慢数组是一个哈希表，相比慢数组性能较差。当索引大于当前容量1024和快数组的容量扩容了三倍会变成慢数组，从而减少内存空间。当慢数组能够存储在快数组中，长度在smi之间(SMI 的意思就是Small Integer 的缩写，SMI 对应这Int31)且节省了50%的空间，那么会变成快数组


**隐藏类**

v8为了提高在内存中查找对象属性的效率，通过给每个对象建立隐藏类记录偏移量，通过偏移量去查找属性在内存中的位置。v8为了实现隐藏类，借鉴了静态语言，它假设对象的形状是不会发生变化的，也就是创建后不会添加和删除对象的属性。一旦发生形状的变化，那么隐藏类会被重新构建，这对于 V8 的执行效率来说，是一笔大的开销。同时如果多个对象属性以及属性的顺序相同，那么对象会共用一个隐藏类。所以给我们带来的提示是不能用delete删除变量，尽量一次性初始化对象，多个对象有相同的属性保持属性顺序一致。

**有了快属性为什么还要有隐藏类**

应该说快属性，是建立在隐藏类基础上的，对象查找属性，先通过名字，在隐藏类中找到偏移量，然后在线性结构 properties 中拿到值！但是在键值过多时，properties 变成字典结构，这时就没有隐藏类偏移量一说，会从字典结构比较慢的查找


**内联缓存IC**

内联缓存简单来说就是在运行过程中，收集一些数据信息，将这部分信息缓存起来然后在再次执行的时候可以直接利用这些信息，有效的节省了再次获取这些信息的消耗，从而提高性能。比如我们在查找一个对象的属性时，找对象的隐藏类，再通过隐藏类查找属性偏移量，然后根据偏移量获取属性值，如果函数会被反复执行，那么获取 属性的 流程也需要反复被执行。v8为了简化再次查找过程，以提升对象的查找效率使用了内联缓存。IC 会为每个函数维护一个反馈向量 ，反馈向量记录了函数在执行过程中的一些关键的中间数据。反馈向量其实就是一个表结构，它由很多项组成的，每一项称为一个插槽 (Slot)V8 会依次将执行函数的中间数据写入到反馈向量的插槽中。每个插槽中包括了插槽的索引 (slot index)、插槽的类型 (type)、插槽的状态 (state)、隐藏类 (map) 的地址、还有属性的偏移量。有了反馈向量缓存的临时数据，V8 就可以缩短对象属性的查找路径，从而提升执行效率。但是针对函数中的同一段代码，如果对象的隐藏类是不同的，那么反馈向量也会记录这些不同的隐藏类，这就出现了多态和超态的情况。我们在实际项目中，要尽量避免出现多态或者超态的情况。

一个反馈向量的一个插槽中可以包含多个隐藏类的信息，那么：如果一个插槽中只包含 1 个隐藏类，那么我们称这种状态为单态 (monomorphic)；如果一个插槽中包含了 2～4 个隐藏类，那我们称这种状态为多态 (polymorphic)；如果一个插槽中超过 4 个隐藏类，那我们称这种状态为超态 (magamorphic)。


**v8-compile-cache**

v8 是一个 JIT(Just in time) 编译器。与传统的解释器一行一行执行不同的是，JIT 会在执行脚本前，对源码先解析（parsing）、再编译（compiling)，速度相比前者提升了不少。但解析和编译仍然消耗时间。v8为了能将中间结果缓存起来，就支持了 code caching 的功能。减少二次执行的构建时间，加快脚本的整体执行速度。因为node.js 通过 require 来连接代码，v8-compile-cache的主要作用就是对所有 require 的 module 进行编译并缓存结果。v8-compile-cache 的使用很简单，直接require就行，首先会检查用户是否开启了code caching，如果支持就做持久化，持久化的时候首先在硬盘生成写入地址，然后存储生成的二进制 code caching，建立一个map对象存储脚本到二进制文件的映射。最后将require hook和存储的二进制文件关联起来。关联的时候会重写原生模块的require方法，在require方法内部先创建一个node的 wrapper function，然后对文件内容生成散列，接着读取已经生成 code cache。然后给 vm.Script 去执行。vm.Script 并不会运行脚本，只负责编译，最后返回一个 compiledWraper包装到 module.exports。

**v8 sparkplug**
旧的 V8 架构中包括了两个阶段： Ignition （一个 JavaScript 解释器），和 TurboFan （一个高度优化的编译器），Ignition 使用 JavaScript 抽象语法树去生成 V8 字节码，而 TurboFan 使用这些字节码生成机器码。引入 Sparkplug 的原因是因为在 Ignition 和 TurboFan 之间有一个巨大的性能差异；长时间驻留在解释器中，意味着我们无法获得优化的好处，但是太早调用 TurboFan 又意味着，我们在优化那些不属于热点代码的函数，甚至更糟，它意味着我们在做些不必要的事。我们可以用一个简单且快速的非优化编译器去缩小这个差距，这样可以通过线性遍历字节码并吐出机器码，快速地、低成本地从解释器中分层。，Sparkplug 的速度来源于两个因素。首先，它依赖于 TurboFan 生成的字节码，这意味着大量的工作已经完成了，包括变量解析、判断圆括号是否是箭头函数、为解构声明语句进行脱糖等等。此外，Sparkplug 并不生成任何中间产物，而是在一个单一的线性通道中输出机器码。这种方式意味着 Sparkplug 不能做任何基于中间产物的高级优化，它必须全面移植到每个新的平台上。在性能方面，Sparkplug编译时间和 Ignition 编译器大致相同（因为只是抽象语法树到字节码，不包括解析），大概比 TurboFan 快二到三个量级。，除了性能，Sparkplug 带来的另一个关键收益是减少 CPU 的占用。



